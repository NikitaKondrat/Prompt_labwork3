import sys
import types

# –°–æ–∑–¥–∞—ë–º "–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π" –º–æ–¥—É–ª—å langchain —Å –Ω—É–∂–Ω—ã–º–∏ –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
if "langchain" not in sys.modules:
    fake_langchain = types.ModuleType("langchain")
    fake_langchain.debug = False
    fake_langchain.llm_cache = None  # ‚Üê –¥–æ–±–∞–≤–ª–µ–Ω–æ!
    sys.modules["langchain"] = fake_langchain

import os
import warnings
from openai import OpenAI
from langchain_chroma import Chroma
from langchain_core.embeddings import Embeddings
from typing import List

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è RAG
from langchain_gigachat import GigaChat
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
warnings.filterwarnings('ignore')
os.environ['LANGCHAIN_WARNING'] = 'false'
os.environ['LANGCHAIN_TRACING'] = 'false'
os.environ['LANGCHAIN_VERBOSE'] = 'false'


# === –≠–º–±–µ–¥–¥–∏–Ω–≥-—Ñ—É–Ω–∫—Ü–∏—è (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ Chroma) ===
client = OpenAI(
    api_key="ZmJhMjUwZTItMDg0ZC00N2E3LWIyNDktYjA4MTQyZGFmMGE4.97f6d089a16317c3aa93b365eda739a8",
    base_url="https://foundation-models.api.cloud.ru/v1"
)

class CustomEmbeddings(Embeddings):
    def __init__(self, client, model="BAAI/bge-m3"):
        self.client = client
        self.model = model

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        for text in texts:
            try:
                response = self.client.embeddings.create(input=[text], model=self.model)
                embeddings.append(response.data[0].embedding)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
                embeddings.append([0.0] * 1024)
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        try:
            response = self.client.embeddings.create(input=[text], model=self.model)
            return response.data[0].embedding
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return [0.0] * 1024


embeddings = CustomEmbeddings(client)

# === –ó–ê–ì–†–£–ó–ö–ê –°–£–©–ï–°–¢–í–£–Æ–©–ï–ì–û ChromaDB ===
print("–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞...")
vectorstore = Chroma(
    persist_directory="./chroma_db",
    embedding_function=embeddings,
    collection_name="arxiv_papers"
)
print("–í–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ!")

retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 100}
)


# === RAG: –Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å ===
llm = GigaChat(
    credentials="YTViNDBiOGUtNzE2MS00MmQ1LWE5NmYtZjEzOWYwZjQzZjAxOmU3MTQzOGYxLTc4ZWMtNDFkZS05MzkzLWIxNDQ4NThmMThkOQ==",
    scope="GIGACHAT_API_B2B",
    model="GigaChat-2-Max",
    verify_ssl_certs=False,
)


# === –ü—Ä–æ–º–ø—Ç ===
prompt_template = """–¢—ã -- –Ω–∞—É—á–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ -- –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏–∑ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π ArXiv.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ
2. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –£–∫–∞–∑—ã–≤–∞–π, –∏–∑ –∫–∞–∫–∏—Ö —Å—Ç–∞—Ç–µ–π –≤–∑—è—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —á–µ—Ç–∫–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ
5. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π, –±—É–¥—å —Ç–æ—á–Ω—ã–º

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π:
{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}

–û—Ç–≤–µ—Ç:"""

prompt = ChatPromptTemplate.from_template(prompt_template)


# === –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ===
def format_docs(docs):
    context_parts = []
    for i, doc in enumerate(docs, 1):
        context_parts.append(f"[–î–æ–∫—É–º–µ–Ω—Ç {i}]")
        context_parts.append(doc.page_content)
        if doc.metadata:  # –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –±—ã–ª–æ doc.meta
            context_parts.append(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {doc.metadata}")
        context_parts.append("")
    return "\n".join(context_parts)


# === RAG-—Ü–µ–ø–æ—á–∫–∞ ===
rag_chain = (
    {
        "context": retriever | format_docs,
        "question": RunnablePassthrough()
    }
    | prompt
    | llm
)


# === –¢–ï–°–¢–û–í–´–ô –ó–ê–ü–†–û–° (—á—Ç–æ–±—ã —á—Ç–æ-—Ç–æ –≤—ã–≤–µ–ª–æ—Å—å!) ===
print("\nüîç –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...\n")
try:
    question = "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏?"
    print(f"–í–æ–ø—Ä–æ—Å: {question}\n")
    response = rag_chain.invoke(question)
    print(f"–û—Ç–≤–µ—Ç:\n{response.content}")
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ RAG-–∑–∞–ø—Ä–æ—Å–∞: {e}")